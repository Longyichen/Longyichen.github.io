@InProceedings{10.1007/978-981-99-7224-1_21,
author="Chen, Yilong
and Cui, Shiyao
and Huang, Kun
and Wang, Shicheng
and Tang, Chuanyu
and Liu, Tingwen
and Fang, Binxing",
editor="Wang, Haofen
and Han, Xianpei
and Liu, Ming
and Cheng, Gong
and Liu, Yongbin
and Zhang, Ningyu",
title="Improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views",
booktitle="Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence",
year="2023",
publisher="Springer Nature Singapore",
address="Singapore",
pages="273--284",
abstract="Knowledge graph construction (KGC) aims to build the semantic network which expresses the relationship between named entities. Despite the success of prior studies, it is struggling to accommodate existing KGC models with evolving entity-relation knowledge schema. In this paper, we propose a schema-adaptive KGC method driven by the instruction-tuning large language models (LLM). We fine-tune a LLM with tailored KGC corpus, through which the generalization ability of LLMs are transfered for KGC with evolving schema. To alleviate the bias of a single LLM, we integrate the superiority of several expert models to derive credible results from multiple perspectives. We further boost KGC performances via an elaborately designed schema-constrained decoding strategy and a LLM-guided correction module. Experimental results validate the advantages of our proposed method. Besides, our method achieved the first place in the first task of CCKS-2023 Knowledge Graph Construction.",
isbn="978-981-99-7224-1"
}

